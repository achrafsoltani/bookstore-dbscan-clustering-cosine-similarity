In the digital era, the vast amount of available information and content has made it increasingly challenging for users to discover relevant items that match their preferences. To address this issue, recommendation systems have emerged as essential tools across a wide range of industries, including e-commerce, entertainment, social media, and online learning. These systems aim to personalize the user experience by suggesting products, services, or content that align with individual tastes, thereby improving user satisfaction and engagement.

\vspace{0.5\baselineskip}

Among the various approaches to recommendation, similarity-based techniques have gained significant attention due to their interpretability and computational efficiency. Cosine similarity, in particular, has proven to be a robust metric for measuring the closeness between users or items represented in high-dimensional feature spaces. This method quantifies the orientation between vectors rather than their magnitude, making it well-suited for comparing patterns of preferences or item characteristics.

\vspace{0.5\baselineskip}

The development of effective recommendation systems also depends heavily on the quality of the data and the way features are engineered. Feature selection, normalization, and transformation are critical steps in building meaningful representations that capture user behavior and item properties. While advanced models such as matrix factorization and deep learning have demonstrated high performance, simpler models based on cosine similarity remain valuable, especially when interpretability, speed, or limited data are key constraints.

\vspace{0.5\baselineskip}

In this paper, we explore the construction of a recommendation system that leverages cosine similarity to suggest books to users. This book recommendation scenario serves as a case study for applying and evaluating key methodological choices in data preprocessing and similarity computation. While our current work is focused on the design and exploration phases, it establishes a foundation for subsequent performance evaluation and potential integration with clustering or visualization techniques to enhance interpretability.
